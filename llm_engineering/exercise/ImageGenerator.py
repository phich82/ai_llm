import base64
import io
import os
import requests
import torch

from diffusers import DiffusionPipeline
from dotenv import load_dotenv
from io import BytesIO
from openai import OpenAI
from openai.types import ImagesResponse
from PIL import Image
from PIL.ImageFile import ImageFile

from AIChat import AIChat
from Util import Util

load_dotenv(override=True)


class ImageGenerator:

    __base_url: str = ''
    __model: str = 'dall-e-3' # For ChatHPT
    __provider: str = 'StableDiffusion' # StableDiffusion, GPT
    __client: OpenAI = None

    def __init__(self, model: str=None, provider: str='StableDiffusion', base_url: str=None):
        self.__base_url = base_url if base_url != None and base_url != '' else self.__base_url
        self.__model = model if model != None and model != '' else self.__model
        self.__provider = provider if provider != None and provider != '' else self.__provider
        if self.__provider != 'StableDiffusion':
            if self.__client is None:
                self.__client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

    def __get_device(self, device: str=None):
        if device is not None and device != '':
            return device
        return 'cuda' if torch.cuda.is_available() else 'cpu'

    def generate(self,
                 prompt: str=None,
                 size: str='512x512',
                 base_url: str='http://127.0.0.1:7860',
                 timeout: float=60*60) -> ImageFile:
        """Generate image from text

        Args:
            prompt (str, optional): User prompt. Defaults to None.
            size (str, optional): Height and width of image will be generated (height x width). Defaults to '512x512'.
            base_url (_type_, optional): Stable Diffusion API base url. Defaults to 'http://127.0.0.1:7860'.

        Returns:
            ImageFile: Image File
        """
        # GPT
        if self.__provider == 'GPT':
            return self.generate_by_gpt(prompt=prompt, size=size, timeout=timeout)

        # StableDiffusion
        if self.__provider == 'StableDiffusion':
            return self.generate_by_stable_diffusion(prompt=prompt, size=size, base_url=base_url, timeout=timeout)

        # Default (huggingface)
        return self.generate_by_huggingface(prompt=prompt, size=size, timeout=timeout)

    def generate_by_gpt(self,
                        prompt: str=None,
                        size: str='512x512',
                        response_format: str='b64_json',
                        timeout: float=60*60) -> ImageFile:
        """Generate image from text by GPT

        Args:
            prompt (str, optional): User prompt. Defaults to None.
            size (str, optional): Height and width of image will be generated (height x width). Defaults to '512x512'.
            response_format (str, optional): Response format. Defaults to 'b64_json'.

        Returns:
            ImageFile: Image File
        """
        print(f'Image generated by GPT with model ({self.__model})')
        image_response: ImagesResponse = self.__client.images.generate(
                model=self.__model,
                prompt=prompt,
                size=size,
                n=1,
                response_format=response_format, # url, b64_json
                timeout=timeout
            )
        image_base64 = image_response.data[0].b64_json
        generated_image = Image.open(BytesIO(base64.b64decode(image_base64)))
        return generated_image

    def generate_by_stable_diffusion(self,
                                     prompt: str=None,
                                     size: str='512x512',
                                     base_url: str='http://127.0.0.1:7860',
                                     timeout: float=60*60) -> ImageFile:
        """Generate image from text by Stable Diffusion

        Args:
            prompt (str, optional): User prompt. Defaults to None.
            size (str, optional): Height and width of image will be generated (height x width). Defaults to '512x512'.
            base_url (_type_, optional): Stable Diffusion API base url. Defaults to 'http://127.0.0.1:7860'.

        Returns:
            ImageFile: Image File
        """
        print('Image generated by Stable Diffusion')
        base_url = base_url if base_url != None and base_url != '' else self.__base_url
        sizes = size.split('x')
        height = int(sizes[0])
        width = int(sizes[1])
        payload = {
            "prompt": prompt,
            "height": height,
            "width": width,
            "steps": 20,
            "batch_size": 1,
            "cfg_scale": 7,

            "sampler_index": "DPM++ 2M", # Sampling Method: DPM++ 2M, Euler a
            "scheduler": "Automatic", # Automatic, Karras, Uniform, Normal, Simple, DDIM...
            "sd_model_name": "v1-5-pruned-emaonly",

            # "denoising_strength": 0,
            # "enable_hr": False,
            # "eta": 0,
            # "firstphase_height": 0,
            # "firstphase_width": 0,
            # "n_iter": 1,
            # "negative_prompt": "",
            # "prompt": "example prompt",
            # "restore_faces": False,
            # "s_churn": 0,
            # "s_noise": 1,
            # "s_tmax": 0,
            # "s_tmin": 0,
            # "seed": -1,
            # "seed_resize_from_h": -1,
            # "seed_resize_from_w": -1,
            # "styles": [],
            # "subseed": -1,
            # "subseed_strength": 0,
            # "tiling": False,
        }
        url = f'{base_url}/sdapi/v1/txt2img'
        print(f'Endpoint for text to image: {url}')
        response = requests.post(url=url, json=payload, timeout=timeout)
        result = response.json()

        # result: TextToImageResponse(images: list[str], parameters: dict, info: str)
        # print(f'Result: {result}')

        generated_image: ImageFile = None

        for i in result['images']:
            base64_image = i.split(",", 1)[0]
            generated_image = Image.open(io.BytesIO(base64.b64decode(base64_image)))

        return generated_image

    def generate_by_huggingface(self,
                                prompt: str=None,
                                size: str='512x512',
                                timeout: float=60*60) -> ImageFile:
        """Generate image from text by Stable Diffusion via HuggingFace Pipeline

        Args:
            prompt (str, optional): User prompt. Defaults to None.
            size (str, optional): Height and width of image will be generated (height x width). Defaults to '512x512'.
            timeout (int, optional): Timeout. Defaults to 3600 (1 hour).

        Returns:
            ImageFile: Image File
        """
        print('Image generated by Stable Diffusion via HuggingFace Pipeline')
        device = self.__get_device()
        image_generator  = DiffusionPipeline.from_pretrained(
            'stabilityai/stable-diffusion-2',
            torch_dtype=torch.float16,
            use_safetensors=True,
            variant='fp16'
        ).to(device)
        result = image_generator(prompt=prompt)
        # image = result.images[0]
        # return image
        generated_image: ImageFile = None

        for i in result['images']:
            base64_image = i.split(",", 1)[0]
            generated_image = Image.open(io.BytesIO(base64.b64decode(base64_image)))

        return generated_image

